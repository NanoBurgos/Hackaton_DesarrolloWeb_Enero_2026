{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13634977",
   "metadata": {},
   "source": [
    "# **Diagrama Simple de Arquitectura**\n",
    "\n",
    "        Google Maps -> Scraper Python (externo) -> SQLite Database (.db) -> API REST Backend ->  Frontend Web -> Freelancers.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc8e7c",
   "metadata": {},
   "source": [
    "# **Decisiones que tomar:**\n",
    "\n",
    "1. **El scraping funciona fuera o dentro de la web? : Para hacerlo desde la web**\n",
    "\n",
    "**Scraping fuera de la página** (script externo / backend) : Un script en Python que scrapea Google Maps, guarda los datos en, y la web solo lee esa base de datos.\n",
    "\n",
    "**PROS:**\n",
    "\n",
    "- mas seguro, por que no hay riesgo de exponer credenciales\n",
    "\n",
    "- mas estable, por que no depende del navegador del usuario\n",
    "\n",
    "- mejor performance, el scraping corre una sola vez\n",
    "\n",
    "- arquitectura bien organizada, data -> backend -> frontend\n",
    "\n",
    "- cumple mejor con los limites (no se satura de peticiones a la API)\n",
    "\n",
    "**CONTRAS:**\n",
    "\n",
    "- Requiere un script a parte para poblar la base de datos\n",
    "\n",
    "- No es en tiempo real, pero sirve para la demo del funcionamiento de la pagina \n",
    "\n",
    "\n",
    "**Scraping desde la página (frontend / navegador)**: JavaScript en el navegador del usuario que intenta scrapear directamente Google Maps.\n",
    "\n",
    "**PROS:**\n",
    "\n",
    "- Relativamente mas simple\n",
    "\n",
    "- No necesita backend\n",
    "\n",
    "**CONTRAS:** \n",
    "\n",
    "- Bloqueos constantes por parte de google\n",
    "\n",
    "- Google maps bloquea los bots, hace que los resultados se carguen mas lento en caso de no bloquear del todo\n",
    "\n",
    "- Código expuesto (mala práctica), el codigo sera visible al inspecccionar la web\n",
    "\n",
    "- Cada usuario vuelve a scrapear, dependiendo la cantidad de usuarios, con todas esas peticiones, se puede volver mas lenta la obtencion de resultados esperados\n",
    "\n",
    "- Riesgo muy alto de que google bloquee la ip \n",
    "\n",
    "- No escalable\n",
    "\n",
    "Al tener tantos contras, no se si es viable del todo y por el poco tiempo que tenemos, creo que la mejor opcion sera que el scraping este fuera de la pagina web\n",
    "\n",
    "RESPUESTA FINAL: \n",
    "\n",
    "- el scraping debe hacerse fuera de la pagina\n",
    "\n",
    "- la web solo consumira datos que ya fueron procesados (BD real o ficticio?)\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "2. **Tipo de Base de Datos a utilizar**\n",
    "\n",
    "Comparación rápida de opciones reales\n",
    "\n",
    "| Base de datos\t|¿Conviene?\t|Motivo|\n",
    "|:-:|:-:|:-:|\n",
    "|SQLite|\t✅ SÍ |(mejor opción)\tSimple, robusta, cero setup|\n",
    "|PostgreSQL|\t⚠️ Overkill\t|Potente, pero innecesaria|\n",
    "|MySQL|\t⚠️ Similar a Postgres|\tRequiere servidor|\n",
    "|MongoDB|\t❌ No\t|No necesitás documentos|\n",
    "|Firebase|\t❌ No\t|Vendor lock-in, mala para scraping|\n",
    "|CSV / JSON|\t❌ No|\tSin integridad ni consultas|\n",
    "|Redis|\t❌ No|\tCache, no base principal|\n",
    "\n",
    "**Elegi SQLite porque:**\n",
    "\n",
    "A nivel técnico SQLite es:\n",
    "\n",
    "- Relacional\n",
    "\n",
    "- Embebida\n",
    "\n",
    "- Basada en archivo\n",
    "\n",
    "- Extremadamente estable\n",
    "\n",
    "**Ventajas técnicas clave**\n",
    "\n",
    "1. **No necesita servidor**\n",
    "\n",
    "- No hay daemon\n",
    "\n",
    "- No hay puertos\n",
    "\n",
    "- No hay configuración\n",
    "\n",
    "2. **Ideal para scraping**\n",
    "\n",
    "- Muchas lecturas\n",
    "\n",
    "- Escrituras batch (cuando corre el scraper)\n",
    "\n",
    "- Soporta índices, joins, filtros complejos\n",
    "\n",
    "3. Integración perfecta con Python\n",
    "\n",
    "- sqlite3 viene en la librería estándar\n",
    "\n",
    "- Pandas, SQLAlchemy, FastAPI, Flask → todos lo soportan\n",
    "\n",
    "- No necesitmos drivers externos.\n",
    "\n",
    "4. Atomicidad garantizada\n",
    "\n",
    "Cuando el scraper corre:\n",
    "\n",
    "- O guarda todo\n",
    "\n",
    "- O no guarda nada\n",
    "\n",
    "No quedan datos corruptos si el proceso falla. \n",
    "\n",
    "5. Performance real\n",
    "\n",
    "- Hasta decenas de miles de registros sin problemas\n",
    "\n",
    "- Con índices funciona sorprendentemente rápido\n",
    "\n",
    "Google Chrome, WhatsApp y Android usan SQLite internamente\n",
    "\n",
    "**¿Por qué NO PostgreSQL o MySQL?**\n",
    "\n",
    "PostgreSQL (gran base de datos)\n",
    "\n",
    "- Muy potente\n",
    "- ❌ Necesita servidor \n",
    "- ❌ Setup largo\n",
    "- ❌ Innecesario para un dataset scrapeado\n",
    "\n",
    "**¿Por qué NO MongoDB (NoSQL)?**\n",
    "\n",
    "- ❌ Consultas más complejas para filtros simples\n",
    "\n",
    "RESPUESTA FINAL: \n",
    "- Usamos SQLite porque es una base de datos liviana y confiable que se guarda en un solo archivo.\n",
    "\n",
    "- Nuestro sistema obtiene los datos automáticamente, los guarda de forma segura y la página web solo los lee, lo que hace que el sistema sea rápido, estable y fácil de mantener.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "3. **Base de Datos real o ficticia**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
